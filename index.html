<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Proposal Ideas</title>
    <link rel="stylesheet" href="index.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
            inlineMath: [['\\(', '\\)']],
            displayMath: [['\\[', '\\]']],
            processEscapes: true
        },
        "HTML-CSS": { scale: 90 },
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.5/gsap.min.js" integrity="sha512-cOH8ndwGgPo+K7pTvMrqYbmI8u8k6Sho3js0gOqVWTmQMlLIi6TbqGWRTpf1ga8ci9H3iPsvDLr4X7xwhC/+DQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.5/ScrollTrigger.min.js" integrity="sha512-AMl4wfwAmDM1lsQvVBBRHYENn1FR8cfOTpt8QVbb/P55mYOdahHD4LmHM1W55pNe3j/3od8ELzPf/8eNkkjISQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/Observer.min.js" integrity="sha512-7xTD1meeGGoAzwZKA0Z8YelV3qAvRltuwACWXpnxtneF7VAMztOTAi3t4laVSaE4Znq4LMPeGUIYWEvKEk5r3Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/Draggable.min.js" integrity="sha512-S6SXKUZ11xkCoD/UuhdXG4B4iiCXng+xW2KCx0lgfQqmdqtjqGgm4WChdYIhO1F/CmH21vnkSUvPEgXNgDwkjg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="index.js" defer></script>
</head>
<body>
    <div class="intro">
        <div class="word" data-value="Some">Some</div>
        <div class="word" data-value="Proposal">Proposal</div>
        <div class="word" data-value="Ideas">Ideas</div>
    </div>

    <div class="grid">
        <div class="cont">
          <h1>Van Oort, Schröder, & French, 2011</h1>
        </div>
           <div class="cont">
          <h1>Introduction to Response Processes</h1>
        </div>
           <div class="cont">
          <h1>Response Processes in Health Psychology</h1>
        </div>
        <div class="cont">
          <h1>IRT Parameters in Non-cognitive Measures</h1>
        </div>
        <div class="cont">
          <h1>Analysis Plan for SSHRC</h1>
        </div>
          
          
    </div>

    <div class="content">
        <div class="cross"><i class ="fa fa-xmark-square"></i></div>
        <div class="c1">
            <h2 class="heading">Van Oort, Schröder, & French, 2011</h2>
            <p class="para">The "think-aloud" study in this paper focuses on understanding how patients interpret and respond to the Brief Illness Perception Questionnaire (Brief IPQ).</p>
            <p class="para">Since our primary concern is the coding scheme for this study, i only focused on that moving forward.</h2>
            <h2 class="heading">Think-Aloud Studies</h2>
            <p class="para">Think-aloud studies are a type of qualitative research in which participants are asked to verbalize their thoughts while performing a task. The goal is to understand their thoughts, perceptions, misunderstandings, and decision-making strategies. </p>
            <p class="center">Steps</p>
            <ol>
                <li><b>Data Collection:</b> Participants 'think aloud' while completing the questionnaire, verbalizing their thoughts and reactions to each question.</li>
                <li><b>Transcription and Analysis:</b> The verbalizations are transcribed and then analyzed. Each response or reaction is categorized into one of the above categories.</li>
                <li><b>Inter-Rater Reliability:</b> To ensure objectivity and accuracy, more than one researcher is involved in the coding process. Discrepancies in categorization are discussed until a consensus is reached.</li>
                <li><b>Identifying Patterns:</b> The frequency and types of issues identified in each category are analyzed to identify patterns or common themes.</li>
                <li><b>Implications for Questionnaire Design:</b> The findings are used to assess the content validity of the questionnaire and guide potential revisions or improvements.</li>
              </ol>
            <h2 class="heading">Initial Coding Categories</h2>
            <ol>
              <p class="center">No Significant Problems Identified:</p>
              <li> This category was for instances where the participant did not exhibit any apparent difficulty in understanding or answering the question.</li>
              <p class="center">Participant Reread Question or Stumbled in Answering</p>
              <li>This category included moments where participants had to reread a question or stumbled (like stammering or stuttering) while answering, suggesting problems in understanding the question.</li>
              <p class="center">Questioned Content of Question</p>
              <li>This category was for instances where participants explicitly questioned how a question was worded, indicating a problem with the phrasing or content of the question.</li>
              <p class="center">Answered a Different Question or Gave Inconsistent Reasoning</p>
              <li>This category captured instances where participants either answered a different question from what was asked or provided reasoning that was inconsistent with their answer, indicating a misinterpretation of the question.</li>
            </ol>
            <h2 class="heading">Revised Coding Categories</h2>
            <ol>
              <p class="center">No Significant Problems Identified</p>
              <li>
                  This category includes instances where participants completed a question without any apparent difficulty. It indicates that the participant understood the question as intended and was able to provide a response without hesitation or confusion.
              </li>
              <p class="center">Reread Question or Stumbled in Reading</p>
              <li>
                  Participants reread a question or had difficulty reading it (e.g., stuttering or stammering). This suggests a potential ambiguity or complexity in the question's wording, causing the participant to double-check their understanding.
              </li>
              <p class="center">Difficulty Generating an Answer</p>
              <li>
                  Here, participants struggled to formulate an answer. This could be due to the question being too broad, vague, or not resonating with their experience. It reflects a disconnect between the participant's thoughts or experiences and the question's framing.
              </li>
              <p class="center">Difficulty Responding by Means of Numbers</p>
              <li>
                  Participants found it challenging to express their thoughts or feelings using the numerical scale provided by the questionnaire. This category highlights the difficulty in quantifying subjective experiences into a predefined numerical format.
              </li>
              <p class="center">Questioned Content of Question</p>
              <li>
                  Instances where participants explicitly questioned the wording, relevance, or meaning of a question. It indicates a possible issue with how the question is perceived, suggesting that it might not be capturing the intended construct accurately.
              </li>
              <p class="center">Answered a Different Question or Gave Inconsistent Reasoning</p>
              <li>
                  Participants either answered a question that was not asked (misinterpretation) or their reasoning did not align with the answer given. This suggests a significant misunderstanding of the question, pointing to issues in clarity or relevance to the participant's situation.
              </li>
          </ol>
          <h2 class="heading">Table of general steps</h2>
          <table border="1">
            <tr>
              <th>Step</th>
              <th>Description</th>
            </tr>
            <tr>
              <td>1. Design the Study</td>
              <td>
                <ul>
                  <li>Objective: What are you trying to compare between the likert format and the expanded format? (understanding, ease, accuracy).</li>
                  <li>Questionnaire Development: Create or pick an existing questionnaire with original and expanded Likert formats. Additionally, make sure the scale is fully validated and reliable. </li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>2. Participant Selection</td>
              <td>
                <ul>
                  <li>Recruitment: Try to recruit from a diverse participant group.</li>
                  <li>Inclusion Criteria: Make sure to account for cultural differences and ensure comfort with language and capability for think-aloud process using that language.</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>3. Preparation for Data Collection</td>
              <td>
                <ul>
                  <li>Training Session: Before engaging in the think aloud exercise make sure to brief participants on think-aloud process.</li>
                  <li>Next, you'd want to conduct a test to refine the protocol and formats.</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>4. Data Collection</td>
              <td>
                <ul>
                  <li>Administration of Questionnaires: Randomly assign participants to questionnaire formats from a diverse representative pool. </li>
                  <li>Recording: Audio/video record verbalizations during completion and generate appropriate transcripts. </li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>5. Data Analysis</td>
              <td>
                <ul>
                  <li>Coding:  Once the transcripts of the recordings have been generated, categorize responses using a coding scheme.</li>
                  <li>Comparison: Analyze and compare responses between likert and expanded format using some statistical procedure.</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>6. Interpretation and Reporting</td>
              <td>
                <ul>
                  <li>Findings: Summarize key differences and similarities by visualizing (2 way contingency tables, mosiac displays, association plots, stratified  analysis) and modelling the data (Log linear Models, Tests of association)</li>
                  <li>Implications: Discuss implications for questionnaire design.</li>
                  <li>Limitations and Recommendations: Acknowledge study limitations and suggest future research.</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>7. Ethical Considerations</td>
              <td>
                <ul>
                  <li>Informed Consent: Ensure all participants provide informed consent.</li>
                  <li>Confidentiality: Maintain participant data confidentiality.</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>8. Feedback and Revision</td>
              <td>
                <ul>
                  <li>Participant Feedback: Conduct debrief for additional feedback (optional).</li>
                  <li>Questionnaire Revision: Revise format based on findings.</li>
                </ul>
              </td>
            </tr>
          </table>
          <h2 class="heading">Proposal Steps</h2>
          <ol>
            <p class="center">Introuction and Background:</p>
            <li>Introduce the topic of your research, highlighting its importance and relevance.
              Present background information on Likert scales and the need for exploring expanded formats.
            </li>
            <p class="center">Literature Review:</p>
            <li>Summarize existing studies and theories related to Likert scales and questionnaire design.
              Identify gaps in the current research that your project aims to fill.</li>
            <p class="center">Research Question:</p>
            <li>Clearly state the objectives of your research.
              Formulate specific research questions that you plan to answer.</li>
            <p class="center">Methodology:</p>
            <li>Describe the think-aloud method in detail.
              Explain how participants will be selected, how data will be collected, and the process of questionnaire administration.
              Outline the steps for transcription and coding of verbalizations.</li>
            <p class="center">Statistical Analysis Plan:</p>
            <li>Discuss the statistical methods you will use to compare the responses between the two formats.
              For analyzing the data categorized into 6 levels, consider using ordinal logistic regression or multinomial logistic regression, as these are suitable for categorical dependent variables with more than two levels.</li>
            <p class="center">Significance and Impact:</p>
            <li>Explain the potential impact of your research findings on questionnaire design and data collection methods.
              Highlight how your research contributes to the broader field of survey methodology and psychology.</li>
            <p class="center">Limitations and Future Research:</p>
            <li>Discuss the limitations of your study and how they might affect the results.
              Suggest future research that could address these limitations.</li>
            <p class="center">Ethical and Monetary Considerations:</p>
            <li>Provide a detailed timeline for each phase of your project, from the preparation to data collection, analysis, and reporting.
              Present a plan that includes participant incentives, data analysis software, and any other resources needed.
              Address how you will handle informed consent, participant confidentiality, and other ethical aspects. Summarize the importance of the project and its expected contributions.</li>
          </ol>
          <h2 class="heading">Visualizations</h2>
          <ol>
              <p class="center">Mosaic Display</p>
              <li>Designed to help to visualize the pattern of associations among variables in two-way and larger tables.
                Extensions of this technique can reveal partial associations, marginal associations, and shed
                light on the structure of loglinear models themselves.</li>
              <p class="center">Effect Plots</p>
              <li>Effect plots are a graphical method for displaying the results of a statistical model. </li>
              <p class="center">Association Plot</p>
              <li>Association plots, often used in the context of categorical data analysis, visually represent the strength and direction of relationships between categorical variables in a contingency table. </li>
          </ol>


          <h2 class="heading">Statistical Ideas</h2>
          <p class="center">Chi-Squared test of association</p>
          <p>Chi-Square Test of Independence: For initial analysis, to see if there are significant differences in the distribution of categories between the two formats.</p>
            <p class="para center">Ordinal/Multinomial Logistic Regression:</p>
            <p>his is suitable if the categories have a natural order (e.g., from no problems to severe problems). Multinomial Logistic Regression is suitable if the categories do not have a natural order (e.g., from no problems to severe problems).</p>
            <p class="para center">Log Linear Models</p>
            <p>Log Linear Models are suitable for analyzing categorical data with more than two variables. They can be used to analyze the association between the format and the other variables in the dataset.</p>
            <p class="para center">Multinomial Logit Models</p>
            <p>They are a type of regression model used for predicting the outcome of a categorical dependent variable based on one or more predictor variables.</p>
        </div>
        <div class="c1">
          <h2 class="heading">Introduction to Response processes</h2>
          <p class="para">In the current standards for Educational and Psychological Testing, there is a lack of a precise definition of response processes despite their significance in understanding the fit between constructs and the actual responses given by test takers. <span class="red">Response processes can be summarized as follows - </span></p>
          <ol>
            <li><span class="red">Definition:</span>  Response processes are mechanisms underlying what individuals do, think, or feel when interacting with test items, extending beyond cognition to include emotions, motivations, and behaviors. They stress the need to identify these underlying mechanisms rather than merely observing surface-level expressions.</li>
            <li><span class="red">Historically, </span>  there has been a predominant focus on cognitive models of responding in research. The authors argue that response processes may involve multiple measurable mental operations and phases.</li>
            <li><span class="red">Ways to analyze response processes: </span> There exist various techniques beyond cognitive processes for gathering validity evidence based on response processes, including response times, eye tracking, analyzing relationships among test components, paradata, anthropological data, and computational models. Furthermore, we should examinine the processes used by observers, scorers, or judges in evaluating respondents.</li>
          </ol>

          <h2 class="heading">Validating Response Processes</h2>
          <p>Several studies (Beckman, Cook, & Mandrekar, 2005; Cizek, Rosenberg, & Koon, 2008; Villalobos Coronel, 2015; Zumbo & Chan, 2012) have highlighted that response processes wwere significantly neglected in validation research. In recent years there has been an influx of research incorporating response processess in scale validation especially in the medical community however, these studies focused solely on the technical and procedural aspects, which might have inflate the reported prevalence of evidence based on response processes without truly reflecting the intended meaning. The scarcity of 
            validation based on response processes can be attributed to the lack of clear and established practices on how to design and report such studies.
          </p>
          <h2 class="heading">Next Steps</h2>
          <p>To correctly utilize and encourage the examination of response processes in validation research there needs to be a shift in understanding and investigating response processes.</p>
          <table>
            <tr>
              <th>Key Points</th>
              <th>Summary</th>
            </tr>
            <tr>
              <td>Addressing the Gap in Understanding</td>
              <td>
                We need more explanation-based research in response processes, moving beyond simple descriptive accounts. 
              </td>
            </tr>
            <tr>
              <td>Understanding response processes in Validation Research</td>
              <td>
                To truly understand response processes in validation research, there needs to be an emphasis on its role in broadening the understanding and utilization of response processes as validity evidence. Researchers should offer conceptual models, methodological considerations, applications, and examples to aid in gathering response processes evidence in validation work.
              </td>
            </tr>
            <tr>
              <td>Interdisciplinary adaptation</td>
              <td>
               We should further stop treating measurement research as separate sub-disciplines. Instead, we can recognize the commonalities among various fields like language testing, educational testing, psychological assessment, health measurement, and medical education. The shared language of validity and validation can facilitate learning and advancement across these fields.
              </td>
            </tr>
            <tr>
              <td>Expanding Notions of Response Processes</td>
              <td>
                We need to challenge existing conceptualizations of response processes, extending the evidential basis and methodology beyond traditional methods like think aloud protocols and cognitive interviewing and further adopt a scientific mindset to develop explanatory models for test validation purposes, encompassing cognitive, ecological, disciplinary, affective, motivational, statistical, and psychometric models.
              </td>
            </tr>
            <tr>
              <td>The Role of Explanatory Models</td>
              <td>
                We should place a higher level of importance on explanatory models, it highlights their utility in understanding responses. These models allow viewing items and assessment tasks as windows into respondents' minds and aid in describing the conditions facilitating item responses.
              </td>
            </tr>
          </table>
          
        </div>
        <div class="c1">
          <h2 class="heading">Response Processes in Health Psychology</h2>
          <p>This chapter delves into the significance of measurement devices within health psychology, especially focusing on psychological assessments through questionnaires. It emphasizes the need for these assessments to be both reliable and valid, to provide accurate and trustworthy information about the variables under atudy.</p>
          <h2 class="heading">Measurement Approaches</h2>
          <ol>
              <p class="center">Behavioral Observations:</p>
              <li>This involves direct observation of behaviors related to health and illness. For instance, assessing patient compliance through checklists or tracking health-related behaviors in natural settings.</li>
              <p class="center">Healthcare Records:</p>
              <li>Utilizing existing healthcare records provides information about morbidity, mortality, medical history, treatments, and outcomes. These records offer insights into health conditions and their progression.</li>
              <p class="center">Physiological Assessments:</p>
              <li>Involves measuring physical parameters like blood pressure, heart rate, body composition, or biochemical markers. These assessments provide objective data about the physiological aspects of health.</li>
              <p class="center">Psychophysiological Assessments:</p>
              <li>Techniques like functional magnetic resonance imaging (fMRI) or electroencephalography (EEG) measure physiological responses associated with psychological processes. They reveal how psychological factors manifest physiologically.</li>
              <p class="center">Psychological Questionnaires:</p>
              <li>These tools delve into various psychological processes, attitudes, beliefs, emotions, and behaviors related to health. They often involve self-report measures and are critical for understanding subjective experiences and mental states.</li>
          </ol>
          <h2 class="heading">Methodological Procedures in Psychological Assessments</h2>
          <ol>
            <li>
              <p class="center"><strong>Reliability:</strong></p>
              <p>Reliability aims to ensure consistency and stability in measurement outcomes over time and across different conditions or observers. This includes employing standardized administration procedures, conducting pilot testing, and assessing internal consistency using statistical measures.</p>
            </li>
            <li>
              <p class="center"><strong>Validity:</strong></p>
              <p>Establishing the validity of the assessment tool involves ensuring that the instrument measures what it intends to measure. Procedures include content validation, construct validation, criterion-related validation, and ensuring the instrument's sensitivity to changes over time.</p>
            </li>
            <li>
              <p class="center"><strong>Response Processes:</strong></p>
              <p>These aim to understand the mechanisms underlying how individuals respond to psychological questionnaires. This involves exploring cognitive, affective, and motivational aspects that influence responses, employing techniques like cognitive interviewing or analyzing response times to enhance understanding and improve the validity of these assessments.</p>
            </li>
          </ol>
          <h2 class="heading">Messick's Unified Validity Framework</h2>
          <p class="center">Construct Aspect of Validity</p>
          <p>According to Messick (1989, 1995), validity is not inherent to an instrument or questionnaire but resides in the inferences drawn from participants' responses.</p>
          <p>Messick's view focuses on ensuring trustworthy interpretations of scores by using concepts that explain test performance and how scores relate to other variables (Construct Validity).</p>
          <p class="center">Content Validity</p>
          <p>The goal is to ensure that questionnaire items directly align with and represent the content of the construct under study. Goal is to outline the theory, making the construct different from similar things, and identifying what might change or affect it.</p>
          <p class="center">Substantive Aspect of Validity</p>
          <p>Checking if people's answers match what the questionnaire aims to measure. Methods like talking through thoughts (Cognitive Interviewing and Think Aloud Studies), indirect measures, and observing behavior ensure this alignment.</p>
          <p class="center">Other Aspects of Validity</p>
          <table border="1">
            <tr>
              <th>Validity Aspect</th>
              <th>Description</th>
            </tr>
            <tr>
              <td>Structural Aspect</td>
              <td>Examining internal structure via factor analysis and item loadings.</td>
            </tr>
            <tr>
              <td>Generalizability Aspect</td>
              <td>Assessing applicability across diverse populations or contexts.</td>
            </tr>
            <tr>
              <td>External Aspect</td>
              <td>Investigating relationships with other relevant variables.</td>
            </tr>
            <tr>
              <td>Consequential Aspect</td>
              <td>Exploring broad implications from using a specific test or assessment.</td>
            </tr>
          </table>
          <p class="center">Consequences of neglecting Validtiy</p>
          <p>Disregarding validity considerations risks inaccurate interpretations and misdirection in decision-making processes in both educational and health settings.</p>
          <p class="center">Methods to Support the Validity of Response Processes in Health Psychology</p>
          <p>There are various methodological approaches to optimize the substantive aspects of validity related to participants' responses - </p>
          <h3 class="heading">Think-Aloud Studies</h2>
          <p>In think aloud studies, participants complete questionnaires independently and discuss their thoughts about the questionnaire items, aiding in content analysis and identifying issues or alternative interpretations.</p>
          <p>Through questions like “What does this question mean to you?” or “Did you understand how to answer?”, participants' verbalizations are recorded and analyzed, enabling researchers to pinpoint problematic areas in questionnaire items.</p>
          <p class="center">Use in Psychology</p>
          <p>Think-Aloud studies can help uncover information about retrieval issues and divergent interpretations in assessments like theory of planned behavior questionnaires. Furthermore, they can be crucial when adapting questionnaires for new populations revealing distinct strategies employed by the new population in responding to items. Examples of use include modifications in item wording, alterations in response formats, and omission of items in studies assessing parenting behaviors in adolescent health promotion, ensuring alignment with intended constructs.</p>
          <h2 class="heading">Implicit Measures</h2>
          <p>Implicit measures, like the Implicit Association Test (IAT), assess the attitudes or cognition of participants without conscious awareness of their impact. They differ from explicit questionnaires, focusing on hidden biases or thoughts. They 
            showcase superior predictive capabilities for <span class="red">spontaneous behaviors</span> compared to explicit measures, which excel in <span class="red">deliberate behaviors</span>. They sidestep the need for introspection seen in explicit assessments, offering an alternative lens to examine responses (Gawronski & De Houwer, 2014). Implicit measures tend to mitigate response biases and social desirability concerns prevalent in explicit methods, enabling a more authentic evaluation of attitudes or cognitions (Gawronski & Bodenhausen, 2006). There is an additional emphasis on the effectiveness of explicit measures in understanding psychological processes, implicit measures demonstrate predictive utility in health behavior studies (Keatley et al., 2012). However, there are concerns associated with the arbitrary scoring metrics of implicit measures, prompting ongoing psychometric evaluations to enhance their meaningfulness and address bias issues (Blanton et al., 2015a, 2015b). 
          </p>
          <h2 class="heading">Behavioural Assessments</h2>
          <p class="center">Eye-Tracking Assessments:</p>
          <ol>
                <li>Allows evaluation of cognitive processes related to health-related stimuli with change in behavior.</li>
                <li>Assesses attention and cognitive processing of gain- versus loss-framed health messages objectively, without relying on introspection.</li>
                <li>Gain-framed messages tend to attract more attention and cognitive processing compared to loss-framed ones, indicating potential impact on health behaviors.</li>
                <li>Eye-tracking technology offers an unbiased way to gauge where attention is directed, bypassing memory decay and social desirability biases common in self-report questionnaires.</li>
          </ol>
          <p class="center">Gain-framed messages:</p>
            <ol>
                <li>Emphasize the positive outcomes or benefits of taking action.</li>
                <li>Highlight what individuals stand to gain by engaging in a behavior.</li>
                <li>Focus on rewards, advantages, or improvements associated with the action.</li>
            </ol>

          <p class="center">Loss-framed messages:</p>
          <ol>
              <li>Emphasize the negative consequences or risks of not taking action.</li>
              <li>Highlight what individuals might lose or face if they don't engage in a behavior.</li>
              <li>Focus on potential drawbacks, adverse outcomes, or losses associated with inaction.</li>
          </ol>


          <p class="center">Performance-Based Assessments (Emotional Intelligence - EI):</p>
          <ol>
                <li>Assesses emotional intelligence (EI) through abilities in perceiving, using, understanding, and managing emotions.</li>
                <li>Traditional self-report measures of EI face challenges like self-report bias and lack of discriminant validity.</li>
                <li>The Mayer Salovey Caruso Emotional Intelligence Test (MSCEIT) provides an objective evaluation of emotional problem-solving abilities.</li>
                <li>MSCEIT demonstrates good reliability, factorial validity, and discriminant validity compared to personality measures and intelligence assessments.</li>
                <li>These objective ability-based assessments offer a more direct and reliable evaluation of psychological abilities, enhancing the understanding of constructs like emotional intelligence.</li>
          </ol>

        </div>
        <div class="c1">
          <h2 class="heading">The impact of Measurement Models' Influence on Validity Discussions</h2>
          <ol>
            <li>Validity discussions in measurement and psychometrics are influenced by the employed measurement models such as classical test theory, item response theory (IRT), factor analysis, or axiomatic scaling theory.</li>
            <li>Zumbo (2007) and Hubley with Zumbo (2013) emphasize that these measurement models are not neutral in the validation process; they carry their own values and assumptions, shaping discussions of validity.</li>
          </ol>
          <h2 class="heading">Understanding IRT and the parameters</h2>
          <p>tem Response Theory (IRT) is a statistical model used to describe item analysis and item responding. It estimates parameters to describe response patterns: a-parameter (discrimination), b-parameter (threshold value), c-parameter (lower asymptote), and sometimes d-parameter (upper asymptote).</p>
          <p class="center">IRT Parameters</p>
          <table border="1">
            <tr>
              <th>Parameter</th>
              <th>Description</th>
            </tr>
            <tr>
              <td>a-parameter</td>
              <td>Discrimination parameter, indicates how well an item discriminates between individuals with high and low levels of the construct.</td>
            </tr>
            <tr>
              <td>b-parameter</td>
              <td>Threshold parameter, indicates the level of the construct at which the probability of a positive response is 50%.</td>
            </tr>
            <tr>
              <td>c-parameter</td>
              <td>Lower asymptote parameter, indicates the probability of a positive response when the level of the construct is low.</td>
            </tr>
            <tr>
              <td>d-parameter</td>
              <td>Upper asymptote parameter, indicates the probability of a positive response when the level of the construct is high.</td>
            </tr>
          </table>
          <p>IRT's item response function characterizes the interaction between persons and items, representing a psychological response process rather than merely a statistical model.
            The parameters in IRT, symbolic letters in mathematical terms, carry psychological information about the interaction between the test taker and the item/task, contributing to the validity of the test.</p>
          <h2 class="heading">IRT Parameters in Practice</h2>
          <table border="1">
            <tr>
                <th>Characteristics</th>
                <th>Description</th>
                <th>Relationship with IRT Parameters</th>
                <th>Findings</th>
            </tr>
            <tr>
                <td>Word/Item Abstractness</td>
                <td>Level of generality or specificity in item language</td>
                <td>Correlation with discrimination and difficulty parameters</td>
                <td>Surprisingly small or non-significant correlations observed, contradicting expectations</td>
            </tr>
            <tr>
                <td>Item Subtlety</td>
                <td>Indirectness or nuance in item wording</td>
                <td>Relationship with discrimination and difficulty</td>
                <td>Inconsistent findings across studies: Some indicate negative correlation, others show no significant link</td>
            </tr>
            <tr>
                <td>Word Frequency</td>
                <td>Frequency of words used in items</td>
                <td>Impact on discrimination/difficulty</td>
                <td>Mixed findings in studies: Some report significant correlations, others find no substantial relationship</td>
            </tr>
            <tr>
                <td>Social Desirability</td>
                <td>Respondents' tendency to answer favorably</td>
                <td>Link with lower asymptote (c-parameter)</td>
                <td>Potential positive relationship observed: More socially desirable items might be endorsed despite low underlying traits</td>
            </tr>
        </table>
        <h2 class="heading">Method Section</h2> 
        <p>In this study, two participant groups were involved. The first sample, consisting of 729 adults (316 men, 413 women) aged 16 to 94 years (M = 55.1), completed the GDS (Geriatric Depression Scale) to estimate IRT parameters. They had varying education levels (ranging from 2 to 21 years, M = 12.7).</p>
        <p>A separate community sample of 30 adults (15 men, 15 women) aged 21 to 88 years (M = 42.2) rated the social-cognitive aspects of the GDS items.</p>
        <p>The Geriatric Depression Scale (GDS) used in the study comprises 30 items designed to assess depressive symptoms in older adults but applicable across various adult age ranges. Respondents answered using a dichotomous format (yes/no), where '1' indicated a more depressed response and '0' a non-depressed one. Total scores ranged from 0 to 30, with higher scores indicating more severe depressive symptoms.</p>
        <p>Additionally, the 30 individuals in the second sample evaluated each GDS item based on specific social-cognitive aspects, rating the degree of wording specificity, time taken to respond (availability heuristic), comfort level in responding (emotional comfort), clarity of item meaning (meaning clarity), and the perceived social desirability of the response. These aspects were rated on a 7-point scale ranging from -3 to +3. An example item and rating instructions were provided to guide this rating process, as shown in Fig. 5.1.</p>

        <h2 class="heading">Analyses</h2>
        <table>
          <tr>
            <th>Step</th>
            <th>Description</th>
          </tr>
          <tr>
            <td>Unidimensionality Assessment</td>
            <td>Conducted PCA and parallel analysis to check unidimensionality of GDS responses.</td>
          </tr>
          <tr>
            <td>Application of IRT Models</td>
            <td>Fitted five IRT models (1PL-b, 2PL-a.b, 3PL-a.b.c, 3PL-a.b.d, 4PL-a.b.c.d) to GDS response data.</td>
          </tr>
          <tr>
            <td>Bayesian Estimation</td>
            <td>Used OpenBUGS for Bayesian estimation of item parameters due to non-normal likelihoods.</td>
          </tr>
          <tr>
            <td>Prior Distributions</td>
            <td>Set prior distributions for each parameter based on previous specifications.</td>
          </tr>
          <tr>
            <td>Model Comparison</td>
            <td>Compared models using the Deviance Information Criterion (DIC), selecting 3PL-a.b.d model.</td>
          </tr>
          <tr>
            <td>Item Parameter Estimation</td>
            <td>Estimated a, b, and d parameters for each of the 30 GDS items using the selected model.</td>
          </tr>
          <tr>
            <td>Social-Cognitive Aspects</td>
            <td>Obtained descriptive statistics for social-cognitive aspects (wording specificity, availability heuristic, emotional comfort, meaning clarity, and social desirability).</td>
          </tr>
          <tr>
            <td>Regression Analysis</td>
            <td>Performed multilevel ordinal logistic regression to study associations between item parameters and social-cognitive aspects.</td>
          </tr>
          <tr>
            <td>Outcome</td>
            <td>Revealed nuanced relationships between GDS item characteristics and social-cognitive aspects, contributing to a deeper understanding of their interplay.</td>
          </tr>
        </table>
        <h2 class="heading">Results</h2>
        <table>
          <tr>
            <th>Social-Cognitive Aspect</th>
            <th>Relationship with IRT Parameters</th>
            <th>Effect Size</th>
            <th>Additional Insights</th>
          </tr>
          <tr>
            <td>Wording Specificity</td>
            <td>Negatively related to difficulty (b-parameter), positively related to item phrasing</td>
            <td>Small effect</td>
            <td>Items reflecting depressed symptoms tended to be more specifically worded</td>
          </tr>
          <tr>
            <td>Availability Heuristic</td>
            <td>Negatively related to discrimination (a-parameter)</td>
            <td>Relatively small effect</td>
            <td>No significant relations with difficulty, upper asymptote, or item phrasing</td>
          </tr>
          <tr>
            <td>Emotional Comfort</td>
            <td>No significant relationships found</td>
            <td>N/A</td>
            <td>No significant associations detected</td>
          </tr>
          <tr>
            <td>Meaning Clarity</td>
            <td>No significant relationships found</td>
            <td>N/A</td>
            <td>No significant associations detected</td>
          </tr>
          <tr>
            <td>Social Desirability</td>
            <td>Negatively related to discrimination and difficulty, negatively related to item phrasing</td>
            <td>Small to moderate effects</td>
            <td>Items reflecting depressed symptoms were rated as less socially desirable to endorse</td>
          </tr>
        </table>

        <h2 class="heading">Discussion</h2>
        <table border="1">
          <tr>
            <th>Goals of the Study</th>
            <th>Findings</th>
            <th>Limitations</th>
          </tr>
          <tr>
            <td>Investigate the psychological significance behind Item Response Theory (IRT) parameters, especially in non-cognitive measures.</td>
            <td>
              <ul>
                <li>Emotional comfort and meaning clarity were not significantly associated with any IRT parameters (a, b, or d).</li>
                <li>Discrimination (a-parameter) showed negative correlations with availability heuristic and social desirability ratings.</li>
                <li>Wording specificity and meaning clarity contradicted earlier notions of lower discriminating power with more abstract items.</li>
              </ul>
            </td>
            <td>
              <ul>
                <li>Use of different samples for ratings of item aspects and GDS data collection might introduce subjectivity differences.</li>
                <li>Lack of consistency in findings across studies possibly due to varied model preferences, statistical methods used, or specificity of relationships between IRT parameters and item characteristics.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>Understand two processes: evaluations of different item aspects by raters and which aspects contribute to respondent-item interaction and subsequent response.</td>
            <td>
              <ul>
                <li>Threshold parameter (b, difficulty) had negative associations with wording specificity and social desirability, indicating higher thresholds for vaguer items.</li>
                <li>Upper asymptote (d-parameter) was more relevant than the lower asymptote (c-parameter) in modeling GDS response data.</li>
              </ul>
            </td>
            <td>
              <ul>
                <li>Insufficient power in previous studies might contribute to inconsistencies across research.</li>
                <li>Need for replication of previous studies and consideration of various non-cognitive measures in future research.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>Explore relationships between IRT parameters and social-cognitive aspects such as availability heuristic, emotional comfort, and meaning clarity.</td>
            <td>
              <ul>
                <li>Phrasing of GDS items displayed significant correlations with wording specificity and social desirability, indicating specific yet less socially desirable negatively phrased items.</li>
              </ul>
            </td>
            <td>
              <ul>
                <li>Potential differences in the ratings provided by different samples might affect the overall analysis and interpretations.</li>
                <li>Call for a shift towards richer psychological interpretations in psychometric modeling, beyond purely mathematical approaches.</li>
              </ul>
            </td>
          </tr>
        </table>
        
       
        </div>

        <div class="c1">
          <h2 class="heading">Likert Data and Expanded Data</h2>
          <ol>
            <li><span class="red">First Step:</span> Ensure that responses from both Likert and expanded Likert forms are compatible and aligned correctly for comparison.
              Next, Create a contingency table representing the ratings given by each observer for the same subjects or objects.</li>
            <li><span class="red">Measures of Agreement:</span>  <span class="red">a. Cohen's Kappa:</span>
              Calculate Cohen's Kappa for both Likert and expanded Likert forms separately.
              Kappa measures the agreement between observers while considering agreement by chance.
              <br>
              <span class="red">b. Weighted Kappa:</span>
              If the Likert scale has an ordered structure, consider using weighted Kappa.
              Weighted Kappa accounts for partial agreement, especially if the expanded Likert form allows for different degrees of agreement.</li>
            <li><span class="red">Visualization Agreement:</span> Utilize an observer agreement chart to visually represent the strength and pattern of agreement/disagreement between the two observer groups for both Likert and expanded Likert forms. <br>
              Analyze the pattern: observe where disagreements occur, especially if one observer consistently rates higher or lower than the other.</li>
            <li><span class="red">Statistical Testing: </span> Conduct a Multinomial logistic regression to test a certain hypothesis and evaluate and interpret the odds ratios. </li>
            <li><span class="red">Interpretation:</span>Interpret the results considering the context and nuances of the data. Look for patterns of agreement/disagreement and assess whether the expanded Likert form provides more nuanced or reliable information compared to the regular Likert scale. Examine effect plots at the end. </li>
          </ol>
        </div>


    </div>
</body>
</html>

